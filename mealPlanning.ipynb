{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6624fb3ca54ae50cf2ca77fc2cd0c04ff713ac35"
   },
   "source": [
    "# Using RL to plan Meals within a budget while catering to personal preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c53ce7c333e0bf6f357b3efe990a6e044257e831"
   },
   "source": [
    "## Aim\n",
    "\n",
    "When shopping for groceriesn there are often multiple options for the same ingredient..some cheaper,some of higher quality.The goal of this project is to develop a model that can select the optimal combination of products for a meal that:\n",
    "\n",
    "Stays within a specified budget\n",
    "Aligns with personal preferences\n",
    "\n",
    "The motivation for using a model is scalability..as the number of ingredients and product options grows the complexity quickly surpasses what can be reasonably calculated mentally.A model allows us to handle larger and ore realistic scenarios efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "309d875421b01fe337f15f24283f9a6eb8456d7d"
   },
   "source": [
    "## Method\n",
    "\n",
    "To tackle this problem a simple RL approach is used spcifically Monte Carlo learning to identify the optimal combination of products for a meal.\n",
    "\n",
    "The model can be framed as a Markov Decision Process (MDP):\n",
    "\n",
    "Each required ingredient is considered a State.\n",
    "Each available product for an ingredient represents an Action for that state.\n",
    "Preferences for products are treated as Individual Rewards which will be detailed further later.\n",
    "\n",
    "Monte Carlo learning evaluates the overall quality of each sequence of actions by observing the outcome of the complete combination.Unlike some approaches that update step-by-step,Monte Carlo waits until the full sequence is known before assessing the quality of each choice.\n",
    "\n",
    "While Monte Carlo is often avoided due to the time it takes to simulate full sequences..it is particularly well-suited here. The final evaluation of a meal combination depends on whether the total cost of the selected products stays within the budget.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "33386d7b6704a1b51842be28a4a0857ee6f58b43",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d7d841000db7cfa3136e936d45492b1e38b87a0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SampleData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "40c2e12ef48d0c06bf23191d2791b4e81cbf9725",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f2f37b0be5ab5ecd0b74a482c6ce1c4e75b1523e",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def MCModelv1(data, alpha, e, epsilon, budget, reward):\n",
    "    Ingredients = list(set(data['Ingredient']))\n",
    "    data = data.copy()  # avoid modifying original\n",
    "    data['V'] = data['V_0'].copy()\n",
    "\n",
    "    output = []\n",
    "    output1 = []\n",
    "    output2 = []\n",
    "    action_in_full = []\n",
    "\n",
    "    for episode_idx in range(e):\n",
    "        episode_run = []\n",
    "\n",
    "        for i, ingredient in enumerate(Ingredients):\n",
    "            # epsilon-greedy selection\n",
    "            if episode_idx == 0 or np.random.rand() < epsilon:\n",
    "                # Random selection\n",
    "                possible_products = data.loc[data['Ingredient'] == ingredient, 'Product']\n",
    "                chosen_product = np.random.choice(possible_products)\n",
    "            else:\n",
    "                # Greedy selection based on max V\n",
    "                possible_products = data.loc[data['Ingredient'] == ingredient]\n",
    "                max_v = possible_products['V'].max()\n",
    "                chosen_product = possible_products[possible_products['V'] == max_v]['Product'].iloc[0]\n",
    "\n",
    "            episode_run.append(int(chosen_product))\n",
    "\n",
    "        episode_df = pd.DataFrame({\n",
    "            'Ingredient': Ingredients,\n",
    "            'Product': episode_run\n",
    "        })\n",
    "        episode_df['Merged_label'] = (episode_df['Ingredient']*10 + episode_df['Product']).astype(float)\n",
    "\n",
    "        # Merge with cost and reward\n",
    "        episode_df = episode_df.merge(\n",
    "            data[['QMerged_label', 'Real_Cost']], \n",
    "            left_on='Merged_label', right_on='QMerged_label',\n",
    "            how='inner'\n",
    "        )\n",
    "        # Terminal reward based on budget\n",
    "        episode_df['Return'] = 1 if budget >= episode_df['Real_Cost'].sum() else -1\n",
    "\n",
    "        # Update V values\n",
    "        data = data.merge(\n",
    "            episode_df[['Merged_label', 'Return']],\n",
    "            left_on='QMerged_label', right_on='Merged_label',\n",
    "            how='left'\n",
    "        )\n",
    "        data['Return'] = data['Return'].fillna(0)\n",
    "        data['V'] = data['V'] + alpha * ((data['Return']/len(Ingredients)) - data['V'])\n",
    "\n",
    "        # Remove temporary columns\n",
    "        data = data.drop(columns=['Merged_label', 'Return'], errors='ignore')\n",
    "\n",
    "        # Store outputs\n",
    "        output.append(data['V'].sum())\n",
    "        output1.append(data.iloc[[1,2,4,8]]['V'].sum())\n",
    "        output2.append(data.iloc[[0,3,5,6,7]]['V'].sum())\n",
    "\n",
    "        # Optimal actions per ingredient\n",
    "        optimal_actions = data.loc[data.groupby('Ingredient')['V'].idxmax(), ['Ingredient', 'Product']]\n",
    "        # Randomly select if multiple max\n",
    "        optimal_actions = optimal_actions.groupby('Ingredient')['Product'].apply(\n",
    "            lambda x: x.sample(1).iloc[0]\n",
    "        )\n",
    "        action_in_full.extend(optimal_actions.astype(int))\n",
    "\n",
    "    return (\n",
    "        np.array(output),\n",
    "        np.array(output1),\n",
    "        np.array(output2),\n",
    "        optimal_actions,\n",
    "        data,\n",
    "        np.array(action_in_full)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d2b42e574790be8a6cb696f95c1bebd25696d21d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "alpha = 0.1\n",
    "num_episodes = 100\n",
    "epsilon = 0.5\n",
    "budget = 30\n",
    "\n",
    "# Reward vector (currently all zeros)\n",
    "reward = [0] * 9\n",
    "\n",
    "# Measure execution time\n",
    "start_time = time.time()\n",
    "\n",
    "# Run Monte Carlo model\n",
    "Mdl = MCModelv1(\n",
    "    data=data,\n",
    "    alpha=alpha,\n",
    "    e=num_episodes,\n",
    "    epsilon=epsilon,\n",
    "    budget=budget,\n",
    "    reward=reward\n",
    ")\n",
    "# Print execution time\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "5073a92e9ac087ee29ba16b6c89993c7a324dc1f"
   },
   "outputs": [],
   "source": [
    "print(Mdl[3])\n",
    "\n",
    "Mdl[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "9ad315bedc05747fae1abfabacc8599b2ef5191e"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(0,num_episodes), Mdl[0])\n",
    "plt.title('Sum of V for all Actions at each Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Sum of V')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "959651b3ff1f479edd91fa7e272bf1a3e2688fea"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(0,num_episodes), Mdl[1],range(0,num_episodes), Mdl[2])\n",
    "plt.title('Sum of V for the cheapest actions and others seperated at each Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Sum of V')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3140ed63710d9e9730b7b0282635d3bf7e9884a9"
   },
   "outputs": [],
   "source": [
    "# Get unique ingredients\n",
    "Ingredients = list(set(data['Ingredient']))\n",
    "actions = pd.DataFrame()\n",
    "\n",
    "# Iterate over each ingredient\n",
    "for a, ingredient in enumerate(Ingredients):\n",
    "    # Extract actions selected for this ingredient across all episodes\n",
    "    individual_actions = Mdl[5][a::len(Ingredients)]  \n",
    "    actions[a] = individual_actions\n",
    "    \n",
    "    # Plot the product selection over episodes\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(range(num_episodes), actions[a], marker='o', linestyle='-', markersize=4)\n",
    "    plt.title(f'Product Selection for Ingredient {ingredient}')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Selected Product')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17910040daf6184d63349fdb561f452dd6d5f575"
   },
   "outputs": [],
   "source": [
    "# Create adjusted product columns\n",
    "actions2 = actions.copy()\n",
    "actions2['Product1'] = actions2.iloc[:, 0] + 10\n",
    "actions2['Product2'] = actions2.iloc[:, 1] + 20\n",
    "actions2['Product3'] = actions2.iloc[:, 2] + 30\n",
    "actions2['Product4'] = actions2.iloc[:, 3] + 40\n",
    "\n",
    "# Merge with real costs\n",
    "actions2 = actions2.merge(\n",
    "    data[['QMerged_label', 'Real_Cost']], \n",
    "    left_on='Product1', right_on='QMerged_label', how='left'\n",
    ").rename(columns={'Real_Cost': 'Cost1'})\n",
    "\n",
    "actions2 = actions2.merge(\n",
    "    data[['QMerged_label', 'Real_Cost']], \n",
    "    left_on='Product2', right_on='QMerged_label', how='left'\n",
    ").rename(columns={'Real_Cost': 'Cost2'})\n",
    "\n",
    "actions2 = actions2.merge(\n",
    "    data[['QMerged_label', 'Real_Cost']], \n",
    "    left_on='Product3', right_on='QMerged_label', how='left'\n",
    ").rename(columns={'Real_Cost': 'Cost3'})\n",
    "\n",
    "actions2 = actions2.merge(\n",
    "    data[['QMerged_label', 'Real_Cost']], \n",
    "    left_on='Product4', right_on='QMerged_label', how='left'\n",
    ").rename(columns={'Real_Cost': 'Cost4'})\n",
    "\n",
    "# Calculate total cost\n",
    "actions2['Total_Cost'] = actions2[['Cost1', 'Cost2', 'Cost3', 'Cost4']].sum(axis=1)\n",
    "\n",
    "# Keep only relevant columns and trim to num_episodes\n",
    "actions2 = actions2.iloc[:num_episodes, [0, 1, 2, 3, -1]]\n",
    "\n",
    "# Plot total cost vs budget\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(num_episodes), actions2['Total_Cost'], label='Total Cost')\n",
    "plt.axhline(y=budget, color='k', linestyle='--', linewidth=2, label='Budget')\n",
    "plt.title('Total Real Cost of Selected Products per Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Real Cost (£)')\n",
    "plt.ylim([0, budget + 10])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a2f4dd36aace84bdea24c07685fb94530d5c0c1"
   },
   "outputs": [],
   "source": [
    "# Parameters for very small budget\n",
    "budget2 = 5\n",
    "alpha2 = 0.1\n",
    "num_episodes2 = 100\n",
    "epsilon2 = 0.5\n",
    "reward2 = [0] * 9  # Currently all zeros\n",
    "\n",
    "# Run Monte Carlo model\n",
    "start_time = time.time()\n",
    "Mdl2 = MCModelv1(\n",
    "    data=data,\n",
    "    alpha=alpha2,\n",
    "    e=num_episodes2,\n",
    "    epsilon=epsilon2,\n",
    "    budget=budget2,\n",
    "    reward=reward2\n",
    ")\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
    "\n",
    "# Plot sum of V for all actions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(num_episodes2), Mdl2[0], label='Sum of V (All Actions)')\n",
    "plt.title('Sum of V for All Actions per Episode (Very Small Budget)')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Sum of V')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41edca465c3b169aa1c4f3fafc18e8cbd1091b70"
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "budget3 = 100  # Very large budget\n",
    "alpha3 = 0.1\n",
    "num_episodes3 = 100\n",
    "epsilon3 = 0.5\n",
    "reward3 = [0] * 9  # Currently all zeros\n",
    "\n",
    "# Run Monte Carlo model\n",
    "start_time = time.time()\n",
    "Mdl3 = MCModelv1(\n",
    "    data=data,\n",
    "    alpha=alpha3,\n",
    "    e=num_episodes3,\n",
    "    epsilon=epsilon3,\n",
    "    budget=budget3,\n",
    "    reward=reward3\n",
    ")\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
    "\n",
    "# Plot sum of V for all actions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(num_episodes3), Mdl3[0], label='Sum of V (All Actions)')\n",
    "plt.title('Sum of V for All Actions per Episode (Large Budget)')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Sum of V')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8876e14166674f5aaceddcddf1f9f2c973640e5"
   },
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "budget4 = 23\n",
    "alpha4 = 0.1\n",
    "num_episodes4 = 100\n",
    "epsilon4 = 0.5\n",
    "reward4 = [0] * 9  # Currently all zeros\n",
    "\n",
    "# Run the Monte Carlo model\n",
    "start_time = time.time()\n",
    "Mdl4 = MCModelv1(\n",
    "    data=data,\n",
    "    alpha=alpha4,\n",
    "    e=num_episodes4,\n",
    "    epsilon=epsilon4,\n",
    "    budget=budget4,\n",
    "    reward=reward4\n",
    ")\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
    "\n",
    "# Plot sum of V for all actions\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(num_episodes4), Mdl4[0], label='Sum of V (All Actions)')\n",
    "plt.title('Sum of V for All Actions per Episode')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Sum of V')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot sum of V for cheapest actions vs others\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(num_episodes4), Mdl4[1], label='Cheapest Actions')\n",
    "plt.plot(range(num_episodes4), Mdl4[2], label='Other Actions')\n",
    "plt.title('Sum of V for Cheapest Actions vs Others')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Sum of V')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5559fa135a0563ef9c988702c397b0a4f800a365"
   },
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# display Plotly version info\n",
    "import plotly\n",
    "print(f\"Plotly version: {plotly.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a3bc9503822bd6322be95c2f7fb80c17f0f4b84"
   },
   "outputs": [],
   "source": [
    "# Fixed parameters except alpha\n",
    "budget5 = 23\n",
    "num_episodes5 = 100\n",
    "epsilon5 = 0.5\n",
    "reward5 = [0] * 9  # Currently all zeros\n",
    "\n",
    "# Prepare lists to store results\n",
    "V_list = []\n",
    "alpha_list = []\n",
    "episode_list = []\n",
    "\n",
    "# Loop over alpha values\n",
    "for x in range(10):\n",
    "    alpha5 = 1 - x / 10\n",
    "    Mdl5 = MCModelv1(\n",
    "        data=data,\n",
    "        alpha=alpha5,\n",
    "        e=num_episodes5,\n",
    "        epsilon=epsilon5,\n",
    "        budget=budget5,\n",
    "        reward=reward5\n",
    "    )\n",
    "    # Extend the lists with episode results\n",
    "    V_list.extend(Mdl5[0])\n",
    "    alpha_list.extend([alpha5] * num_episodes5)\n",
    "    episode_list.extend(range(num_episodes5))\n",
    "\n",
    "# Create DataFrame\n",
    "VforInteractiveGraphA2 = pd.DataFrame({\n",
    "    'Alpha': alpha_list,\n",
    "    'Episode': episode_list,\n",
    "    'V': V_list\n",
    "})\n",
    "\n",
    "VforInteractiveGraphA2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e738e8a72a7c5dbb4287aa301ade51bb19c087d5"
   },
   "outputs": [],
   "source": [
    "# Copy data from previous DataFrame\n",
    "VforInteractiveGraphA3 = VforInteractiveGraphA2.copy()\n",
    "\n",
    "# Add extra columns for Plotly visualization\n",
    "VforInteractiveGraphA3['continent'] = 'Test'\n",
    "VforInteractiveGraphA3['country'] = 'Test2'\n",
    "VforInteractiveGraphA3['pop'] = 7000000.0\n",
    "\n",
    "# Rename columns for consistency\n",
    "VforInteractiveGraphA3.columns = ['year', 'lifeExp', 'gdpPercap', 'continent', 'country', 'pop']\n",
    "\n",
    "# Get sorted unique alpha values (years) for slider frames\n",
    "years = np.sort(VforInteractiveGraphA3['year'].unique())[::-1]\n",
    "years = np.round(years, 1)\n",
    "\n",
    "years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6bc2a910af8b9fe2b00a5b628929463742c4eb9"
   },
   "outputs": [],
   "source": [
    "# Use VforInteractiveGraphA3 as dataset\n",
    "dataset = VforInteractiveGraphA3\n",
    "\n",
    "continents = dataset['continent'].unique().tolist()\n",
    "years = np.sort(dataset['year'].unique())[::-1]\n",
    "\n",
    "# Initialize Plotly figure\n",
    "figure = {\n",
    "    'data': [],\n",
    "    'layout': {\n",
    "        'title': \"Parameter Optimisation using Interactive Animation\",\n",
    "        'xaxis': {'title': 'Episode'},\n",
    "        'yaxis': {'title': 'Sum of V', 'type': 'linear'},\n",
    "        'hovermode': 'closest',\n",
    "        'sliders': {},\n",
    "        'updatemenus': [{\n",
    "            'buttons': [\n",
    "                {'args': [None, {'frame': {'duration': 500, 'redraw': False},\n",
    "                                 'fromcurrent': True,\n",
    "                                 'transition': {'duration': 300, 'easing': 'quadratic-in-out'}}],\n",
    "                 'label': 'Play', 'method': 'animate'},\n",
    "                {'args': [[None], {'frame': {'duration': 0, 'redraw': False},\n",
    "                                   'mode': 'immediate',\n",
    "                                   'transition': {'duration': 0}}],\n",
    "                 'label': 'Pause', 'method': 'animate'}\n",
    "            ],\n",
    "            'direction': 'left', 'pad': {'r': 10, 't': 87}, 'showactive': False,\n",
    "            'type': 'buttons', 'x': 0.1, 'xanchor': 'right', 'y': 0, 'yanchor': 'top'\n",
    "        }]\n",
    "    },\n",
    "    'frames': []\n",
    "}\n",
    "\n",
    "# Slider dictionary\n",
    "sliders_dict = {\n",
    "    'active': 0,\n",
    "    'yanchor': 'top',\n",
    "    'xanchor': 'left',\n",
    "    'currentvalue': {'font': {'size': 20}, 'prefix': 'Alpha: ', 'visible': True, 'xanchor': 'right'},\n",
    "    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n",
    "    'pad': {'b': 10, 't': 50},\n",
    "    'len': 0.9,\n",
    "    'x': 0.1,\n",
    "    'y': 0,\n",
    "    'steps': []\n",
    "}\n",
    "\n",
    "# Initial frame (first year/alpha)\n",
    "for continent in continents:\n",
    "    data_by_cont = dataset[dataset['continent'] == continent]\n",
    "    figure['data'].append({\n",
    "        'x': list(data_by_cont['lifeExp']),\n",
    "        'y': list(data_by_cont['gdpPercap']),\n",
    "        'mode': 'markers',\n",
    "        'text': list(data_by_cont['country']),\n",
    "        'marker': {'sizemode': 'area', 'sizeref': 200000, 'size': list(data_by_cont['pop'])},\n",
    "        'name': continent\n",
    "    })\n",
    "\n",
    "# Create frames and slider steps\n",
    "for year in years:\n",
    "    frame = {'data': [], 'name': str(year)}\n",
    "    for continent in continents:\n",
    "        data_by_cont = dataset[(dataset['continent'] == continent) & (np.round(dataset['year'], 1) == np.round(year, 1))]\n",
    "        frame['data'].append({\n",
    "            'x': list(data_by_cont['lifeExp']),\n",
    "            'y': list(data_by_cont['gdpPercap']),\n",
    "            'mode': 'markers',\n",
    "            'text': list(data_by_cont['country']),\n",
    "            'marker': {'sizemode': 'area', 'sizeref': 200000, 'size': list(data_by_cont['pop']), 'color': 'rgba(255,182,193,0.9)'},\n",
    "            'name': continent\n",
    "        })\n",
    "    figure['frames'].append(frame)\n",
    "    sliders_dict['steps'].append({\n",
    "        'args': [[year], {'frame': {'duration': 300, 'redraw': False}, 'mode': 'immediate', 'transition': {'duration': 300}}],\n",
    "        'label': str(year),\n",
    "        'method': 'animate'\n",
    "    })\n",
    "\n",
    "figure['layout']['sliders'] = [sliders_dict]\n",
    "\n",
    "# Display interactive animation\n",
    "from plotly.offline import iplot\n",
    "iplot(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61c5aaabce291d42db50782e531753b373043abb"
   },
   "outputs": [],
   "source": [
    "# Fixed parameters except alpha\n",
    "budget6 = 23\n",
    "num_episodes6 = 100\n",
    "epsilon6 = 0.5\n",
    "reward6 = [0] * 9  # Rewards for actions\n",
    "\n",
    "# Prepare lists for interactive animation\n",
    "V_list, alpha_list, episode_list = [], [], []\n",
    "\n",
    "for x in range(10):\n",
    "    alpha6 = 0.1 - x / 100\n",
    "    Mdl6 = MCModelv1(\n",
    "        data=data,\n",
    "        alpha=alpha6,\n",
    "        e=num_episodes6,\n",
    "        epsilon=epsilon6,\n",
    "        budget=budget6,\n",
    "        reward=reward6\n",
    "    )\n",
    "    \n",
    "    V_list.extend(Mdl6[0])\n",
    "    alpha_list.extend([alpha6] * num_episodes6)\n",
    "    episode_list.extend(range(num_episodes6))\n",
    "\n",
    "# Create DataFrame for Plotly animation\n",
    "df_plot = pd.DataFrame({\n",
    "    'year': alpha_list,      # Alpha values\n",
    "    'lifeExp': episode_list, # Episode numbers\n",
    "    'gdpPercap': V_list      # Sum of V\n",
    "})\n",
    "\n",
    "# Add bubble simulation columns\n",
    "df_plot['continent'] = 'Test'\n",
    "df_plot['country'] = 'Test2'\n",
    "df_plot['pop'] = 7_000_000.0\n",
    "\n",
    "# Unique alpha values for slider frames\n",
    "alpha_values = np.sort(df_plot['year'].unique())[::-1]\n",
    "\n",
    "# Determine continents\n",
    "continents = df_plot['continent'].unique().tolist()\n",
    "\n",
    "# Initialize Plotly figure\n",
    "figure = {\n",
    "    'data': [],\n",
    "    'layout': {\n",
    "        'title': \"Parameter Optimisation using Interactive Animation\",\n",
    "        'xaxis': {'title': 'Episode'},\n",
    "        'yaxis': {'title': 'Sum of V', 'type': 'linear'},\n",
    "        'hovermode': 'closest',\n",
    "        'sliders': {},\n",
    "        'updatemenus': [{\n",
    "            'buttons': [\n",
    "                {'args': [None, {'frame': {'duration': 500, 'redraw': False},\n",
    "                                 'fromcurrent': True,\n",
    "                                 'transition': {'duration': 300, 'easing': 'quadratic-in-out'}}],\n",
    "                 'label': 'Play', 'method': 'animate'},\n",
    "                {'args': [[None], {'frame': {'duration': 0, 'redraw': False},\n",
    "                                   'mode': 'immediate',\n",
    "                                   'transition': {'duration': 0}}],\n",
    "                 'label': 'Pause', 'method': 'animate'}\n",
    "            ],\n",
    "            'direction': 'left', 'pad': {'r': 10, 't': 87}, 'showactive': False,\n",
    "            'type': 'buttons', 'x': 0.1, 'xanchor': 'right', 'y': 0, 'yanchor': 'top'\n",
    "        }]\n",
    "    },\n",
    "    'frames': []\n",
    "}\n",
    "\n",
    "# Slider dictionary\n",
    "sliders_dict = {\n",
    "    'active': 0, 'yanchor': 'top', 'xanchor': 'left',\n",
    "    'currentvalue': {'font': {'size': 20}, 'prefix': 'Alpha: ', 'visible': True, 'xanchor': 'right'},\n",
    "    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n",
    "    'pad': {'b': 10, 't': 50}, 'len': 0.9, 'x': 0.1, 'y': 0, 'steps': []\n",
    "}\n",
    "\n",
    "# Initial data for the first frame\n",
    "for continent in continents:\n",
    "    data_by_cont = df_plot[df_plot['continent'] == continent]\n",
    "    figure['data'].append({\n",
    "        'x': list(data_by_cont['lifeExp']),\n",
    "        'y': list(data_by_cont['gdpPercap']),\n",
    "        'mode': 'markers',\n",
    "        'text': list(data_by_cont['country']),\n",
    "        'marker': {'sizemode': 'area', 'sizeref': 200_000, 'size': list(data_by_cont['pop'])},\n",
    "        'name': continent\n",
    "    })\n",
    "\n",
    "# Create frames and slider steps\n",
    "for alpha in alpha_values:\n",
    "    frame = {'data': [], 'name': str(alpha)}\n",
    "    for continent in continents:\n",
    "        data_by_cont = df_plot[(df_plot['continent'] == continent) & (np.round(df_plot['year'], 2) == np.round(alpha, 2))]\n",
    "        frame['data'].append({\n",
    "            'x': list(data_by_cont['lifeExp']),\n",
    "            'y': list(data_by_cont['gdpPercap']),\n",
    "            'mode': 'markers',\n",
    "            'text': list(data_by_cont['country']),\n",
    "            'marker': {'sizemode': 'area', 'sizeref': 200_000, 'size': list(data_by_cont['pop']), 'color': 'rgba(255,182,193,0.9)'},\n",
    "            'name': continent\n",
    "        })\n",
    "    figure['frames'].append(frame)\n",
    "    sliders_dict['steps'].append({\n",
    "        'args': [[alpha], {'frame': {'duration': 300, 'redraw': False}, 'mode': 'immediate', 'transition': {'duration': 300}}],\n",
    "        'label': str(alpha),\n",
    "        'method': 'animate'\n",
    "    })\n",
    "\n",
    "figure['layout']['sliders'] = [sliders_dict]\n",
    "\n",
    "iplot(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5302372421bf7fb23cf8844e868338c7773e582"
   },
   "outputs": [],
   "source": [
    "# Fixed parameters except epsilon\n",
    "budget7 = 23\n",
    "num_episodes7 = 100\n",
    "alpha7 = 0.05\n",
    "reward7 = [0] * 9  # Rewards for actions\n",
    "\n",
    "# Prepare lists for interactive animation\n",
    "V_list, epsilon_list, episode_list = [], [], []\n",
    "\n",
    "for x in range(11):\n",
    "    epsilon7 = 1 - x / 10\n",
    "    Mdl7 = MCModelv1(\n",
    "        data=data,\n",
    "        alpha=alpha7,\n",
    "        e=num_episodes7,\n",
    "        epsilon=epsilon7,\n",
    "        budget=budget7,\n",
    "        reward=reward7\n",
    "    )\n",
    "    \n",
    "    # Vectorized append for all episodes\n",
    "    V_list.extend(Mdl7[0])\n",
    "    epsilon_list.extend([epsilon7] * num_episodes7)\n",
    "    episode_list.extend(range(num_episodes7))\n",
    "\n",
    "# Create DataFrame for Plotly animation\n",
    "df_plot = pd.DataFrame({\n",
    "    'year': epsilon_list,      # Epsilon values\n",
    "    'lifeExp': episode_list,   # Episode number\n",
    "    'gdpPercap': V_list        # Sum of V\n",
    "})\n",
    "\n",
    "# Add bubble simulation columns\n",
    "df_plot['continent'] = 'Test'\n",
    "df_plot['country'] = 'Test2'\n",
    "df_plot['pop'] = 7_000_000.0\n",
    "\n",
    "# Unique epsilon values for slider frames\n",
    "epsilon_values = np.sort(df_plot['year'].unique())[::-1]\n",
    "\n",
    "# Determine continents\n",
    "continents = df_plot['continent'].unique().tolist()\n",
    "\n",
    "# Initialize Plotly figure structure\n",
    "figure = {\n",
    "    'data': [],\n",
    "    'layout': {\n",
    "        'title': \"Parameter Optimisation using Interactive Animation\",\n",
    "        'xaxis': {'title': 'Episode'},\n",
    "        'yaxis': {'title': 'Sum of V', 'type': 'linear'},\n",
    "        'hovermode': 'closest',\n",
    "        'sliders': {},\n",
    "        'updatemenus': [{\n",
    "            'buttons': [\n",
    "                {'args': [None, {'frame': {'duration': 500, 'redraw': False},\n",
    "                                 'fromcurrent': True,\n",
    "                                 'transition': {'duration': 300, 'easing': 'quadratic-in-out'}}],\n",
    "                 'label': 'Play', 'method': 'animate'},\n",
    "                {'args': [[None], {'frame': {'duration': 0, 'redraw': False},\n",
    "                                   'mode': 'immediate',\n",
    "                                   'transition': {'duration': 0}}],\n",
    "                 'label': 'Pause', 'method': 'animate'}\n",
    "            ],\n",
    "            'direction': 'left', 'pad': {'r': 10, 't': 87}, 'showactive': False,\n",
    "            'type': 'buttons', 'x': 0.1, 'xanchor': 'right', 'y': 0, 'yanchor': 'top'\n",
    "        }]\n",
    "    },\n",
    "    'frames': []\n",
    "}\n",
    "\n",
    "# Slider dict setup\n",
    "sliders_dict = {\n",
    "    'active': 0, 'yanchor': 'top', 'xanchor': 'left',\n",
    "    'currentvalue': {'font': {'size': 20}, 'prefix': 'Epsilon: ', 'visible': True, 'xanchor': 'right'},\n",
    "    'transition': {'duration': 300, 'easing': 'cubic-in-out'},\n",
    "    'pad': {'b': 10, 't': 50}, 'len': 0.9, 'x': 0.1, 'y': 0, 'steps': []\n",
    "}\n",
    "\n",
    "# Initial data for first frame\n",
    "for continent in continents:\n",
    "    data_by_cont = df_plot[df_plot['continent'] == continent]\n",
    "    figure['data'].append({\n",
    "        'x': list(data_by_cont['lifeExp']),\n",
    "        'y': list(data_by_cont['gdpPercap']),\n",
    "        'mode': 'markers',\n",
    "        'text': list(data_by_cont['country']),\n",
    "        'marker': {'sizemode': 'area', 'sizeref': 200_000, 'size': list(data_by_cont['pop'])},\n",
    "        'name': continent\n",
    "    })\n",
    "\n",
    "# Create frames and slider steps\n",
    "for epsilon in epsilon_values:\n",
    "    frame = {'data': [], 'name': str(epsilon)}\n",
    "    for continent in continents:\n",
    "        data_by_cont = df_plot[(df_plot['continent'] == continent) & (np.round(df_plot['year'], 1) == np.round(epsilon, 1))]\n",
    "        frame['data'].append({\n",
    "            'x': list(data_by_cont['lifeExp']),\n",
    "            'y': list(data_by_cont['gdpPercap']),\n",
    "            'mode': 'markers',\n",
    "            'text': list(data_by_cont['country']),\n",
    "            'marker': {'sizemode': 'area', 'sizeref': 200_000, 'size': list(data_by_cont['pop']), 'color': 'rgba(255,182,193,0.9)'},\n",
    "            'name': continent\n",
    "        })\n",
    "    figure['frames'].append(frame)\n",
    "    sliders_dict['steps'].append({\n",
    "        'args': [[epsilon], {'frame': {'duration': 300, 'redraw': False}, 'mode': 'immediate', 'transition': {'duration': 300}}],\n",
    "        'label': str(epsilon),\n",
    "        'method': 'animate'\n",
    "    })\n",
    "\n",
    "figure['layout']['sliders'] = [sliders_dict]\n",
    "\n",
    "iplot(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b79a593156743b15f1cd4a27434e5eff1b822d9b"
   },
   "outputs": [],
   "source": [
    "# Set budget and hyperparameters\n",
    "budget8 = 23\n",
    "alpha8 = 0.05\n",
    "num_episodes8 = 1000\n",
    "epsilon8 = 0.2\n",
    "\n",
    "# Rewards for actions (currently all zeros)\n",
    "reward8 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Mdl8 = MCModelv1(\n",
    "    data=data,\n",
    "    alpha=alpha8,\n",
    "    e=num_episodes8,\n",
    "    epsilon=epsilon8,\n",
    "    budget=budget8,\n",
    "    reward=reward8\n",
    ")\n",
    "\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
    "\n",
    "# Plot total value per episode\n",
    "plt.plot(range(num_episodes8), Mdl8[0], label=\"Sum of V (all actions)\")\n",
    "plt.title(\"Sum of V for all Actions at each Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Sum of V\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot cheapest vs other actions\n",
    "plt.plot(range(num_episodes8), Mdl8[1], label=\"Cheapest actions\")\n",
    "plt.plot(range(num_episodes8), Mdl8[2], label=\"Other actions\")\n",
    "plt.title(\"Sum of V for Cheapest vs Other Actions per Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Sum of V\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85871506245698835e92918b64318f72f41c2340"
   },
   "outputs": [],
   "source": [
    "def MCModelv2(data, alpha, e, epsilon, budget, reward):\n",
    "    Ingredients = list(set(data['Ingredient']))\n",
    "    data['V'] = data['V_0'].copy()\n",
    "    \n",
    "    output = []\n",
    "    output1 = []\n",
    "    output2 = []\n",
    "    actioninfull = []\n",
    "\n",
    "    for episode_idx in range(e):\n",
    "        episode_run = []\n",
    "\n",
    "        for i in range(len(Ingredients)):\n",
    "            if episode_idx == 0:\n",
    "                # Initialize randomly for first episode\n",
    "                episode_run.append(\n",
    "                    np.random.randint(\n",
    "                        1, sum(1 for p in data.iloc[:, 0] if p == i + 1) + 1\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                if np.random.rand() < epsilon:\n",
    "                    # Explore: random action\n",
    "                    episode_run.append(\n",
    "                        np.random.randint(\n",
    "                            1, sum(1 for p in data.iloc[:, 0] if p == i + 1) + 1\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    # Exploit: choose action with max V\n",
    "                    data_I = data[data['Ingredient'] == (i + 1)]\n",
    "                    max_V_rows = data_I[data_I['V'] == data_I['V'].max()]\n",
    "                    chosen_product = max_V_rows['Product'].values[0]\n",
    "                    episode_run.append(chosen_product)\n",
    "\n",
    "        episode_run = np.array(episode_run, dtype=int)\n",
    "\n",
    "        episode = pd.DataFrame({'Ingredient': Ingredients, 'Product': episode_run})\n",
    "        episode['Merged_label'] = (episode['Ingredient'] * 10 + episode['Product']).astype(float)\n",
    "        data['QMerged_label'] = data['QMerged_label'].astype(float)\n",
    "        data['Reward'] = reward\n",
    "\n",
    "        episode2 = episode.merge(\n",
    "            data[['QMerged_label', 'Real_Cost', 'Reward']],\n",
    "            left_on='Merged_label', right_on='QMerged_label',\n",
    "            how='inner'\n",
    "        )\n",
    "        data = data.drop(columns=['Reward'])\n",
    "\n",
    "        # Terminal reward calculation\n",
    "        Return = budget - episode2['Real_Cost'].sum()\n",
    "        episode2 = episode2.drop(columns=['Reward'])\n",
    "        episode2['Return'] = Return\n",
    "\n",
    "        # Update V values for actions involved in this episode\n",
    "        data = data.merge(\n",
    "            episode2[['Merged_label', 'Return']],\n",
    "            left_on='QMerged_label', right_on='Merged_label',\n",
    "            how='outer'\n",
    "        )\n",
    "        data['Return'] = data['Return'].fillna(0)\n",
    "\n",
    "        for v in range(len(data)):\n",
    "            if data.iloc[v, 7] != 0:\n",
    "                data.iloc[v, 5] += alpha * (data.iloc[v, 7] / len(Ingredients) - data.iloc[v, 5])\n",
    "\n",
    "        data = data.drop(columns=['Merged_label', 'Return'])\n",
    "\n",
    "        # Track outputs\n",
    "        output.append(data['V'].sum())\n",
    "        output1.append(data.iloc[[1, 2, 4, 8], -1].sum())  # cheapest\n",
    "        output2.append(data.iloc[[0, 3, 5, 6, 7], -1].sum())  # expensive\n",
    "\n",
    "        # Determine optimal actions\n",
    "        action_df = data.groupby('Ingredient')['V'].max().reset_index()\n",
    "        action_merge = action_df.merge(data, on='V', how='inner')\n",
    "        action3 = (\n",
    "            action_merge.groupby('Ingredient')['Product']\n",
    "            .apply(lambda x: x.iloc[np.random.randint(0, len(x))])\n",
    "        )\n",
    "        actioninfull.extend(action3.astype(int).tolist())\n",
    "\n",
    "    return np.array(output), np.array(output1), np.array(output2), action3, data, np.array(actioninfull, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cbdd0a1f3266aa0065504c7e46609298c2ee1e78"
   },
   "outputs": [],
   "source": [
    "# Set budget and hyperparameters\n",
    "budget9 = 23\n",
    "alpha9 = 0.05\n",
    "num_episodes9 = 1000\n",
    "epsilon9 = 0.2\n",
    "\n",
    "# Simple rewards (currently all zeros)\n",
    "reward9 = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Mdl9 = MCModelv2(\n",
    "    data=data,\n",
    "    alpha=alpha9,\n",
    "    e=num_episodes9,\n",
    "    epsilon=epsilon9,\n",
    "    budget=budget9,\n",
    "    reward=reward9\n",
    ")\n",
    "\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
    "print(Mdl9[3])\n",
    "\n",
    "# Plot total value per episode\n",
    "plt.plot(range(num_episodes9), Mdl9[0], label=\"Sum of V (all actions)\")\n",
    "plt.title(\"Sum of V for all Actions at each Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Sum of V\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot cheapest vs other actions\n",
    "plt.plot(range(num_episodes9), Mdl9[1], label=\"Cheapest actions\")\n",
    "plt.plot(range(num_episodes9), Mdl9[2], label=\"Other actions\")\n",
    "plt.title(\"Sum of V for Cheapest vs Other Actions per Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Sum of V\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "348726e8f6a698ed6bc24854b21b771760af8513",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def MCModelv3(data, alpha, e, epsilon, budget, reward):\n",
    "    Ingredients = list(set(data['Ingredient']))\n",
    "    data['V'] = data['V_0'].copy()\n",
    "    \n",
    "    output = []\n",
    "    output1 = []\n",
    "    output2 = []\n",
    "    actioninfull = []\n",
    "\n",
    "    for episode_idx in range(e):\n",
    "        episode_run = []\n",
    "\n",
    "        for i in range(len(Ingredients)):\n",
    "            if episode_idx == 0:\n",
    "                # Initialize randomly for first episode\n",
    "                episode_run.append(\n",
    "                    np.random.randint(\n",
    "                        1, sum(1 for p in data.iloc[:, 0] if p == i + 1) + 1\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                if np.random.rand() < epsilon:\n",
    "                    # Explore: random action\n",
    "                    episode_run.append(\n",
    "                        np.random.randint(\n",
    "                            1, sum(1 for p in data.iloc[:, 0] if p == i + 1) + 1\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    # Exploit: choose action with max V\n",
    "                    data_I = data[data['Ingredient'] == (i + 1)]\n",
    "                    max_V_rows = data_I[data_I['V'] == data_I['V'].max()]\n",
    "                    chosen_product = max_V_rows['Product'].values[0]\n",
    "                    episode_run.append(chosen_product)\n",
    "\n",
    "        episode_run = np.array(episode_run, dtype=int)\n",
    "\n",
    "        episode = pd.DataFrame({'Ingredient': Ingredients, 'Product': episode_run})\n",
    "        episode['Merged_label'] = (episode['Ingredient'] * 10 + episode['Product']).astype(float)\n",
    "        data['QMerged_label'] = data['QMerged_label'].astype(float)\n",
    "        data['Reward'] = reward\n",
    "\n",
    "        episode2 = episode.merge(\n",
    "            data[['QMerged_label', 'Real_Cost', 'Reward']],\n",
    "            left_on='Merged_label', right_on='QMerged_label',\n",
    "            how='inner'\n",
    "        )\n",
    "        data = data.drop(columns=['Reward'])\n",
    "\n",
    "        # Terminal reward calculation\n",
    "        if budget >= episode2['Real_Cost'].sum():\n",
    "            Return = 1 + episode2['Reward'].sum() / len(Ingredients)\n",
    "        else:\n",
    "            Return = -1 + episode2['Reward'].sum() / len(Ingredients)\n",
    "\n",
    "        episode2 = episode2.drop(columns=['Reward'])\n",
    "        episode2['Return'] = Return\n",
    "\n",
    "        # Update V values for actions involved in this episode\n",
    "        data = data.merge(\n",
    "            episode2[['Merged_label', 'Return']],\n",
    "            left_on='QMerged_label', right_on='Merged_label',\n",
    "            how='outer'\n",
    "        )\n",
    "        data['Return'] = data['Return'].fillna(0)\n",
    "\n",
    "        for v in range(len(data)):\n",
    "            if data.iloc[v, 7] != 0:\n",
    "                data.iloc[v, 5] += alpha * (data.iloc[v, 7] / len(Ingredients) - data.iloc[v, 5])\n",
    "\n",
    "        data = data.drop(columns=['Merged_label', 'Return'])\n",
    "\n",
    "        # Track outputs\n",
    "        output.append(data['V'].sum())\n",
    "        output1.append(data.iloc[[1, 2, 4, 8], -1].sum())  # cheapest\n",
    "        output2.append(data.iloc[[0, 3, 5, 6, 7], -1].sum())  # expensive\n",
    "\n",
    "        # Determine optimal actions\n",
    "        action_df = data.groupby('Ingredient')['V'].max().reset_index()\n",
    "        action_merge = action_df.merge(data, on='V', how='inner')\n",
    "        action3 = (\n",
    "            action_merge.groupby('Ingredient')['Product']\n",
    "            .apply(lambda x: x.iloc[np.random.randint(0, len(x))])\n",
    "        )\n",
    "        actioninfull.extend(action3.astype(int).tolist())\n",
    "\n",
    "    return np.array(output), np.array(output1), np.array(output2), action3, data, np.array(actioninfull, dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abe0a2a481ba9151b3fbf18af2fff46e67ae69e8"
   },
   "outputs": [],
   "source": [
    "budget10 = 30\n",
    "\n",
    "alpha10 = 0.05\n",
    "num_episodes10 = 1000\n",
    "epsilon10 = 0.2\n",
    "\n",
    "# Simple rewards for selected actions\n",
    "reward10 = [0.8, 0, 0, 0.8, 0, 0, 0, 0, 0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Mdl10 = MCModelv3(\n",
    "    data=data,\n",
    "    alpha=alpha10,\n",
    "    e=num_episodes10,\n",
    "    epsilon=epsilon10,\n",
    "    budget=budget10,\n",
    "    reward=reward10\n",
    ")\n",
    "\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
    "print(Mdl10[3])\n",
    "\n",
    "# Plot total value per episode\n",
    "plt.plot(range(num_episodes10), Mdl10[0], label=\"Sum of V (all actions)\")\n",
    "plt.title(\"Sum of V for all Actions at each Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Sum of V\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot cheapest vs other actions\n",
    "plt.plot(range(num_episodes10), Mdl10[1], label=\"Cheapest actions\")\n",
    "plt.plot(range(num_episodes10), Mdl10[2], label=\"Other actions\")\n",
    "plt.title(\"Sum of V for Cheapest vs Other Actions per Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Sum of V\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "51d29bddacea2de315caf309fc05b621f322446a"
   },
   "outputs": [],
   "source": [
    "budget11 = 30\n",
    "\n",
    "alpha11 = 0.05\n",
    "num_episodes11 = 1000\n",
    "epsilon11 = 0.2\n",
    "\n",
    "# Rewards for actions (can be tuned further)\n",
    "reward11 = [0.8, 0.4, 0.5, 0.6, 0.4, 0.4, 0.6, 0.2, 0.4]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Mdl11 = MCModelv3(\n",
    "    data=data,\n",
    "    alpha=alpha11,\n",
    "    e=num_episodes11,\n",
    "    epsilon=epsilon11,\n",
    "    budget=budget11,\n",
    "    reward=reward11\n",
    ")\n",
    "\n",
    "print(f\"--- {time.time() - start_time:.2f} seconds ---\")\n",
    "print(Mdl11[3])\n",
    "\n",
    "# Plot total value per episode\n",
    "plt.plot(range(num_episodes11), Mdl11[0], label=\"Sum of V (all actions)\")\n",
    "plt.title(\"Sum of V for all Actions at each Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Sum of V\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot cheapest vs other actions\n",
    "plt.plot(range(num_episodes11), Mdl10[1], label=\"Cheapest actions\")\n",
    "plt.plot(range(num_episodes11), Mdl11[2], label=\"Other actions\")\n",
    "plt.title(\"Sum of V for Cheapest vs Other Actions per Episode\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Sum of V\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bafbf50265c6e718b600251e4d19fcf4dd886944"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "This work demonstrates how a Monte Carlo Reinforcement Learning model can be used to recommend products in different ways whether by keeping selections under a budget,choosing the cheapest available option or identifying the best option based on preference while still respecting cost limits..The process highlights how tuning parameters in RL directly shapes outcomes,making it possible to guide the model toward specific goals.While this experiment was carried out on simplified, sample data, the approach holds potential for more practical applications such as recommending ingredients and products from a supermarket where the variety is much larger and the decision-making more complex...Overall the project serves as a step toward exploring RL in real-world recommendation scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97cc458359de02ca6475817f0c9397debe81d458",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 15662,
     "sourceId": 20756,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 104,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
